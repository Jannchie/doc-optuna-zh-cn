# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2018, Optuna Contributors.
# This file is distributed under the same license as the Optuna package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2020.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Optuna 2.2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-10-26 14:44-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:2
msgid "optuna.integration.lightgbm.LightGBMTuner"
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner:1
msgid "Hyperparameter tuner for LightGBM."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner:3
msgid ""
"It optimizes the following hyperparameters in a stepwise manner: "
"``lambda_l1``, ``lambda_l2``, ``num_leaves``, ``feature_fraction``, "
"``bagging_fraction``, ``bagging_freq`` and ``min_child_samples``."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner:7
msgid ""
"You can find the details of the algorithm and benchmark results in `this "
"blog article <https:/ /medium.com/optuna/lightgbm-tuner-new-optuna-"
"integration-for-hyperparameter-optimization-8b709 5e99258>`_ by `Kohei "
"Ozaki <https://www.kaggle.com/confirm>`_, a Kaggle Grandmaster."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner:11
msgid ""
"Arguments and keyword arguments for `lightgbm.train() "
"<https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.train.html>`_"
" can be passed. The arguments that only "
":class:`~optuna.integration.lightgbm.LightGBMTuner` has are listed below:"
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner
msgid "Parameters"
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner:16
msgid "A time budget for parameter tuning in seconds."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner:17
msgid ""
"A :class:`~optuna.study.Study` instance to store optimization results. "
"The :class:`~optuna.trial.Trial` instances in it has the following user "
"attributes: ``elapsed_secs`` is the elapsed time since the optimization "
"starts. ``average_iteration_time`` is the average time of iteration to "
"train the booster model in the trial. ``lgbm_params`` is a JSON-"
"serialized dictionary of LightGBM parameters used in the trial."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner:23
msgid ""
"List of Optuna callback functions that are invoked at the end of each "
"trial. Each function must accept two parameters with the following types "
"in this order: :class:`~optuna.study.Study` and "
":class:`~optuna.FrozenTrial`. Please note that this is not a "
"``callbacks`` argument of `lightgbm.train()`_ ."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner:27
msgid ""
"A directory to save boosters. By default, it is set to :obj:`None` and no"
" boosters are saved. Please set shared directory (e.g., directories on "
"NFS) if you want to access "
":meth:`~optuna.integration.LightGBMTuner.get_best_booster` in distributed"
" environments. Otherwise, it may raise :obj:`ValueError`. If the "
"directory does not exist, it will be created. The filenames of the "
"boosters will be ``{model_dir}/{trial_number}.pkl`` (e.g., "
"``./boosters/0.pkl``)."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner:33
msgid ""
"A verbosity level to change Optuna's logging level. The level is aligned "
"to `LightGBM's verbosity`_ .  .. warning::     Deprecated in v2.0.0. "
"``verbosity`` argument will be removed in the future.     The removal of "
"this feature is currently scheduled for v4.0.0,     but this schedule is "
"subject to change.      Please use :func:`~optuna.logging.set_verbosity` "
"instead."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner:33
msgid ""
"A verbosity level to change Optuna's logging level. The level is aligned "
"to `LightGBM's verbosity`_ ."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner:37
msgid ""
"Deprecated in v2.0.0. ``verbosity`` argument will be removed in the "
"future. The removal of this feature is currently scheduled for v4.0.0, "
"but this schedule is subject to change."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner:41
msgid "Please use :func:`~optuna.logging.set_verbosity` instead."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner:42
msgid ""
"Flag to show progress bars or not. To disable progress bar, set this "
":obj:`False`.  .. note::     Progress bars will be fragmented by logging "
"messages of LightGBM and Optuna.     Please suppress such messages to "
"show the progress bars properly."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner:42
msgid ""
"Flag to show progress bars or not. To disable progress bar, set this "
":obj:`False`."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner:45
msgid ""
"Progress bars will be fragmented by logging messages of LightGBM and "
"Optuna. Please suppress such messages to show the progress bars properly."
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:12
msgid "Methods"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:31:<autosummary>:1
msgid ""
":obj:`compare_validation_metrics "
"<optuna.integration.lightgbm.LightGBMTuner.compare_validation_metrics>`\\"
" \\(val\\_score\\, best\\_score\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:31:<autosummary>:1
msgid ""
":obj:`get_best_booster "
"<optuna.integration.lightgbm.LightGBMTuner.get_best_booster>`\\ \\(\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:31:<autosummary>:1
#: of optuna.integration.lightgbm.LightGBMTuner.best_booster:1
#: optuna.integration.lightgbm.LightGBMTuner.best_booster:1:<autosummary>:1
#: optuna.integration.lightgbm.LightGBMTuner.get_best_booster:1
msgid "Return the best booster."
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:31:<autosummary>:1
msgid ""
":obj:`higher_is_better "
"<optuna.integration.lightgbm.LightGBMTuner.higher_is_better>`\\ \\(\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:31:<autosummary>:1
msgid ":obj:`run <optuna.integration.lightgbm.LightGBMTuner.run>`\\ \\(\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:31:<autosummary>:1
#: of optuna.integration.lightgbm.LightGBMTuner.run:1
msgid "Perform the hyperparameter-tuning with given parameters."
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:31:<autosummary>:1
msgid ""
":obj:`sample_train_set "
"<optuna.integration.lightgbm.LightGBMTuner.sample_train_set>`\\ \\(\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:31:<autosummary>:1
#: of optuna.integration.lightgbm.LightGBMTuner.sample_train_set:1
msgid "Make subset of `self.train_set` Dataset object."
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:31:<autosummary>:1
msgid ""
":obj:`tune_bagging "
"<optuna.integration.lightgbm.LightGBMTuner.tune_bagging>`\\ "
"\\(\\[n\\_trials\\]\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:31:<autosummary>:1
msgid ""
":obj:`tune_feature_fraction "
"<optuna.integration.lightgbm.LightGBMTuner.tune_feature_fraction>`\\ "
"\\(\\[n\\_trials\\]\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:31:<autosummary>:1
msgid ""
":obj:`tune_feature_fraction_stage2 "
"<optuna.integration.lightgbm.LightGBMTuner.tune_feature_fraction_stage2>`\\"
" \\(\\[n\\_trials\\]\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:31:<autosummary>:1
msgid ""
":obj:`tune_min_data_in_leaf "
"<optuna.integration.lightgbm.LightGBMTuner.tune_min_data_in_leaf>`\\ "
"\\(\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:31:<autosummary>:1
msgid ""
":obj:`tune_num_leaves "
"<optuna.integration.lightgbm.LightGBMTuner.tune_num_leaves>`\\ "
"\\(\\[n\\_trials\\]\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:31:<autosummary>:1
msgid ""
":obj:`tune_regularization_factors "
"<optuna.integration.lightgbm.LightGBMTuner.tune_regularization_factors>`\\"
" \\(\\[n\\_trials\\]\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTuner.rst:33
msgid "Attributes"
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner.best_booster:1:<autosummary>:1
msgid ""
":obj:`best_booster "
"<optuna.integration.lightgbm.LightGBMTuner.best_booster>`\\"
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner.best_booster:1:<autosummary>:1
msgid ""
":obj:`best_params "
"<optuna.integration.lightgbm.LightGBMTuner.best_params>`\\"
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner.best_booster:1:<autosummary>:1
#: optuna.integration.lightgbm.LightGBMTuner.best_params:1
msgid "Return parameters of the best booster."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner.best_booster:1:<autosummary>:1
msgid ":obj:`best_score <optuna.integration.lightgbm.LightGBMTuner.best_score>`\\"
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner.best_booster:1:<autosummary>:1
#: optuna.integration.lightgbm.LightGBMTuner.best_score:1
msgid "Return the score of the best booster."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner.best_booster:4
msgid ""
"Deprecated in v1.4.0. This feature will be removed in the future. The "
"removal of this feature is currently scheduled for v3.0.0, but this "
"schedule is subject to change. See "
"https://github.com/optuna/optuna/releases/tag/v1.4.0."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner.best_booster:9
msgid ""
"Please get the best booster via "
":class:`~optuna.integration.lightgbm.LightGBMTuner.get_best_booster` "
"instead."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTuner.get_best_booster:3
msgid ""
"If the best booster cannot be found, :class:`ValueError` will be raised. "
"To prevent the errors, please save boosters by specifying the "
"``model_dir`` arguments of "
":meth:`~optuna.integration.lightgbm.LightGBMTuner.__init__` when you "
"resume tuning or you run tuning in parallel."
msgstr ""

