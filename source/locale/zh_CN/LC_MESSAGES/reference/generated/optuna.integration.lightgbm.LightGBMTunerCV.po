# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2018, Optuna Contributors.
# This file is distributed under the same license as the Optuna package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Optuna 2.4.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-02-17 18:33-0500\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:2
msgid "optuna.integration.lightgbm.LightGBMTunerCV"
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:1
msgid "Hyperparameter tuner for LightGBM with cross-validation."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:3
msgid ""
"It employs the same stepwise approach as "
":class:`~optuna.integration.lightgbm.LightGBMTuner`. "
":class:`~optuna.integration.lightgbm.LightGBMTunerCV` invokes "
"`lightgbm.cv()`_ to train and validate boosters while "
":class:`~optuna.integration.lightgbm.LightGBMTuner` invokes "
"`lightgbm.train()`_. See `a simple example <https://github.com/optuna"
"/optuna-examples/tree/main/lightgbm/ lightgbm_tuner_cv.py>`_ which "
"optimizes the validation log loss of cancer detection."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:11
msgid ""
"Arguments and keyword arguments for `lightgbm.cv()`_ can be passed except"
" ``metrics``, ``init_model`` and ``eval_train_metric``. The arguments "
"that only :class:`~optuna.integration.lightgbm.LightGBMTunerCV` has are "
"listed below:"
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV
msgid "参数"
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:16
msgid "A time budget for parameter tuning in seconds."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:17
msgid ""
"A :class:`~optuna.study.Study` instance to store optimization results. "
"The :class:`~optuna.trial.Trial` instances in it has the following user "
"attributes: ``elapsed_secs`` is the elapsed time since the optimization "
"starts. ``average_iteration_time`` is the average time of iteration to "
"train the booster model in the trial. ``lgbm_params`` is a JSON-"
"serialized dictionary of LightGBM parameters used in the trial."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:23
msgid ""
"List of Optuna callback functions that are invoked at the end of each "
"trial. Each function must accept two parameters with the following types "
"in this order: :class:`~optuna.study.Study` and "
":class:`~optuna.trial.FrozenTrial`. Please note that this is not a "
"``callbacks`` argument of `lightgbm.train()`_ ."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:27
msgid ""
"A directory to save boosters. By default, it is set to :obj:`None` and no"
" boosters are saved. Please set shared directory (e.g., directories on "
"NFS) if you want to access "
":meth:`~optuna.integration.LightGBMTunerCV.get_best_booster` in "
"distributed environments. Otherwise, it may raise :obj:`ValueError`. If "
"the directory does not exist, it will be created. The filenames of the "
"boosters will be ``{model_dir}/{trial_number}.pkl`` (e.g., "
"``./boosters/0.pkl``)."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:34
msgid ""
"A verbosity level to change Optuna's logging level. The level is aligned "
"to `LightGBM's verbosity`_ .  .. warning::     Deprecated in v2.0.0. "
"``verbosity`` argument will be removed in the future.     The removal of "
"this feature is currently scheduled for v4.0.0,     but this schedule is "
"subject to change.      Please use :func:`~optuna.logging.set_verbosity` "
"instead."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:34
msgid ""
"A verbosity level to change Optuna's logging level. The level is aligned "
"to `LightGBM's verbosity`_ ."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:38
msgid ""
"Deprecated in v2.0.0. ``verbosity`` argument will be removed in the "
"future. The removal of this feature is currently scheduled for v4.0.0, "
"but this schedule is subject to change."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:42
msgid "Please use :func:`~optuna.logging.set_verbosity` instead."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:43
msgid ""
"Flag to show progress bars or not. To disable progress bar, set this "
":obj:`False`.  .. note::     Progress bars will be fragmented by logging "
"messages of LightGBM and Optuna.     Please suppress such messages to "
"show the progress bars properly."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:43
msgid ""
"Flag to show progress bars or not. To disable progress bar, set this "
":obj:`False`."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:46
msgid ""
"Progress bars will be fragmented by logging messages of LightGBM and "
"Optuna. Please suppress such messages to show the progress bars properly."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:48
msgid ""
"Flag to enable "
":meth:`~optuna.integration.LightGBMTunerCV.get_best_booster`."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:49
msgid ""
"``seed`` of :class:`~optuna.samplers.TPESampler` for random number "
"generator that affects sampling for ``num_leaves``, ``bagging_fraction``,"
" ``bagging_freq``, ``lambda_l1``, and ``lambda_l2``.  .. note::     The "
"`deterministic`_ parameter of LightGBM makes training reproducible.     "
"Please enable it when you use this argument."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:49
msgid ""
"``seed`` of :class:`~optuna.samplers.TPESampler` for random number "
"generator that affects sampling for ``num_leaves``, ``bagging_fraction``,"
" ``bagging_freq``, ``lambda_l1``, and ``lambda_l2``."
msgstr ""

#: of optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV:54
msgid ""
"The `deterministic`_ parameter of LightGBM makes training reproducible. "
"Please enable it when you use this argument."
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:12
msgid "Methods"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:31:<autosummary>:1
msgid ""
":obj:`compare_validation_metrics "
"<optuna.integration.lightgbm.LightGBMTunerCV.compare_validation_metrics>`\\"
" \\(val\\_score\\, best\\_score\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:31:<autosummary>:1
msgid ""
":obj:`get_best_booster "
"<optuna.integration.lightgbm.LightGBMTunerCV.get_best_booster>`\\ \\(\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:31:<autosummary>:1
#: of
#: optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV.get_best_booster:1
msgid "Return the best cvbooster."
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:31:<autosummary>:1
msgid ""
":obj:`higher_is_better "
"<optuna.integration.lightgbm.LightGBMTunerCV.higher_is_better>`\\ \\(\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:31:<autosummary>:1
msgid ":obj:`run <optuna.integration.lightgbm.LightGBMTunerCV.run>`\\ \\(\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:31:<autosummary>:1
#: of optuna.integration._lightgbm_tuner.optimize._LightGBMBaseTuner.run:1
msgid "Perform the hyperparameter-tuning with given parameters."
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:31:<autosummary>:1
msgid ""
":obj:`sample_train_set "
"<optuna.integration.lightgbm.LightGBMTunerCV.sample_train_set>`\\ \\(\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:31:<autosummary>:1
#: of
#: optuna.integration._lightgbm_tuner.optimize._LightGBMBaseTuner.sample_train_set:1
msgid "Make subset of `self.train_set` Dataset object."
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:31:<autosummary>:1
msgid ""
":obj:`tune_bagging "
"<optuna.integration.lightgbm.LightGBMTunerCV.tune_bagging>`\\ "
"\\(\\[n\\_trials\\]\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:31:<autosummary>:1
msgid ""
":obj:`tune_feature_fraction "
"<optuna.integration.lightgbm.LightGBMTunerCV.tune_feature_fraction>`\\ "
"\\(\\[n\\_trials\\]\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:31:<autosummary>:1
msgid ""
":obj:`tune_feature_fraction_stage2 "
"<optuna.integration.lightgbm.LightGBMTunerCV.tune_feature_fraction_stage2>`\\"
" \\(\\[n\\_trials\\]\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:31:<autosummary>:1
msgid ""
":obj:`tune_min_data_in_leaf "
"<optuna.integration.lightgbm.LightGBMTunerCV.tune_min_data_in_leaf>`\\ "
"\\(\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:31:<autosummary>:1
msgid ""
":obj:`tune_num_leaves "
"<optuna.integration.lightgbm.LightGBMTunerCV.tune_num_leaves>`\\ "
"\\(\\[n\\_trials\\]\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:31:<autosummary>:1
msgid ""
":obj:`tune_regularization_factors "
"<optuna.integration.lightgbm.LightGBMTunerCV.tune_regularization_factors>`\\"
" \\(\\[n\\_trials\\]\\)"
msgstr ""

#: ../../source/reference/generated/optuna.integration.lightgbm.LightGBMTunerCV.rst:33
msgid "Attributes"
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTunerCV.best_params:1:<autosummary>:1
msgid ""
":obj:`best_params "
"<optuna.integration.lightgbm.LightGBMTunerCV.best_params>`\\"
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTunerCV.best_params:1
#: optuna.integration.lightgbm.LightGBMTunerCV.best_params:1:<autosummary>:1
msgid "Return parameters of the best booster."
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTunerCV.best_params:1:<autosummary>:1
msgid ""
":obj:`best_score "
"<optuna.integration.lightgbm.LightGBMTunerCV.best_score>`\\"
msgstr ""

#: of optuna.integration.lightgbm.LightGBMTunerCV.best_params:1:<autosummary>:1
#: optuna.integration.lightgbm.LightGBMTunerCV.best_score:1
msgid "Return the score of the best booster."
msgstr ""

#: of
#: optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV.get_best_booster:3
msgid ""
"If the best booster cannot be found, :class:`ValueError` will be raised. "
"To prevent the errors, please save boosters by specifying both of the "
"``model_dir`` and the ``return_cvbooster`` arguments of "
":meth:`~optuna.integration.lightgbm.LightGBMTunerCV.__init__`, when you "
"resume tuning or you run tuning in parallel."
msgstr ""

#: of
#: optuna.integration._lightgbm_tuner.optimize.LightGBMTunerCV.get_best_booster
#: optuna.integration._lightgbm_tuner.optimize._LightGBMBaseTuner.run
#: optuna.integration._lightgbm_tuner.optimize._LightGBMBaseTuner.sample_train_set
msgid "返回类型"
msgstr ""

#~ msgid ""
#~ "It employs the same stepwise approach"
#~ " as :class:`~optuna.integration.lightgbm.LightGBMTuner`. "
#~ ":class:`~optuna.integration.lightgbm.LightGBMTunerCV` invokes"
#~ " `lightgbm.cv()`_ to train and validate "
#~ "boosters while "
#~ ":class:`~optuna.integration.lightgbm.LightGBMTuner` invokes "
#~ "`lightgbm.train()`_. See `a simple example "
#~ "<https://github.com/optuna/optuna/blob/master/examples/lightgbm_tuner_cv."
#~ " py>`_ which optimizes the validation "
#~ "log loss of cancer detection."
#~ msgstr ""

#~ msgid ""
#~ "It employs the same stepwise approach"
#~ " as :class:`~optuna.integration.lightgbm.LightGBMTuner`. "
#~ ":class:`~optuna.integration.lightgbm.LightGBMTunerCV` invokes"
#~ " `lightgbm.cv()`_ to train and validate "
#~ "boosters while "
#~ ":class:`~optuna.integration.lightgbm.LightGBMTuner` invokes "
#~ "`lightgbm.train()`_. See `a simple example "
#~ "<https://github.com/optuna/optuna/blob/master/examples/lightgbm/ "
#~ "lightgbm_tuner_cv.py>`_ which optimizes the "
#~ "validation log loss of cancer detection."
#~ msgstr ""

#~ msgid ""
#~ "List of Optuna callback functions that"
#~ " are invoked at the end of each"
#~ " trial. Each function must accept two"
#~ " parameters with the following types "
#~ "in this order: :class:`~optuna.study.Study` "
#~ "and :class:`~optuna.FrozenTrial`. Please note "
#~ "that this is not a ``callbacks`` "
#~ "argument of `lightgbm.train()`_ ."
#~ msgstr ""

