# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2018, Optuna Contributors.
# This file is distributed under the same license as the Optuna package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2020.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Optuna 2.2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2020-10-26 14:44-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.8.0\n"

#: ../../source/tutorial/007_pruning.rst:6
msgid ""
"Click :ref:`here <sphx_glr_download_tutorial_007_pruning.py>`     to "
"download the full example code"
msgstr ""

#: ../../source/tutorial/007_pruning.rst:15
msgid "Pruning Unpromising Trials"
msgstr ""

#: ../../source/tutorial/007_pruning.rst:17
msgid ""
"This feature automatically stops unpromising trials at the early stages "
"of the training (a.k.a., automated early-stopping). Optuna provides "
"interfaces to concisely implement the pruning mechanism in iterative "
"training algorithms."
msgstr ""

#: ../../source/tutorial/007_pruning.rst:22
msgid "Activating Pruners"
msgstr ""

#: ../../source/tutorial/007_pruning.rst:23
msgid ""
"To turn on the pruning feature, you need to call "
":func:`~optuna.trial.Trial.report` and "
":func:`~optuna.trial.Trial.should_prune` after each step of the iterative"
" training. :func:`~optuna.trial.Trial.report` periodically monitors the "
"intermediate objective values. :func:`~optuna.trial.Trial.should_prune` "
"decides termination of the trial that does not meet a predefined "
"condition."
msgstr ""

#: ../../source/tutorial/007_pruning.rst:67
msgid "Set up the median stopping rule as the pruning condition."
msgstr ""

#: ../../source/tutorial/007_pruning.rst:82
msgid "Executing the script above:"
msgstr ""

#: ../../source/tutorial/007_pruning.rst:99
msgid ""
"``Trial 5 pruned.``, etc. in the log messages means several trials were "
"stopped before they finished all of the iterations."
msgstr ""

#: ../../source/tutorial/007_pruning.rst:104
msgid "Integration Modules for Pruning"
msgstr ""

#: ../../source/tutorial/007_pruning.rst:105
msgid ""
"To implement pruning mechanism in much simpler forms, Optuna provides "
"integration modules for the following libraries."
msgstr ""

#: ../../source/tutorial/007_pruning.rst:107
msgid ""
"For the complete list of Optuna's integration modules, see "
":mod:`~optuna.integration`."
msgstr ""

#: ../../source/tutorial/007_pruning.rst:109
msgid ""
"For example, :class:`~optuna.integration.XGBoostPruningCallback` "
"introduces pruning without directly changing the logic of training "
"iteration. (See also `example "
"<https://github.com/optuna/optuna/blob/master/examples/pruning/xgboost_integration.py>`_"
" for the entire script.)"
msgstr ""

#: ../../source/tutorial/007_pruning.rst:120
msgid "**Total running time of the script:** ( 0 minutes  1.186 seconds)"
msgstr ""

#: ../../source/tutorial/007_pruning.rst:135
msgid ":download:`Download Python source code: 007_pruning.py <007_pruning.py>`"
msgstr ""

#: ../../source/tutorial/007_pruning.rst:141
msgid ""
":download:`Download Jupyter notebook: 007_pruning.ipynb "
"<007_pruning.ipynb>`"
msgstr ""

#: ../../source/tutorial/007_pruning.rst:148
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

